{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numba\n",
    "from collections import Counter\n",
    "import math\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import sklearn.ensemble\n",
    "import sklearn.cluster\n",
    "import scipy.sparse\n",
    "import keras\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib\n",
    "\n",
    "sys.path += [\"../test\"]\n",
    "from train_clustering import encode_triu, decode_triu\n",
    "from train_regression import get_unique_X_y\n",
    "\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def get_types_in_block(X, y, blk):\n",
    "    return [int(x) for x in sorted(X[y==blk, 0])]\n",
    "\n",
    "def get_blocksize_candsize_matrix(el_bl_id, cand_bl_id):\n",
    "    blids = np.unique(el_bl_id)\n",
    "    sizes = np.zeros((len(blids), 2), dtype=np.float32)\n",
    "    i = 0\n",
    "    els_counter = Counter(el_bl_id)\n",
    "    cands_counter = Counter(cand_bl_id)\n",
    "    for bl in blids:\n",
    "        sizes[i, 0] = els_counter[bl]\n",
    "        sizes[i, 1] = cands_counter[bl]\n",
    "        i += 1\n",
    "        \n",
    "    b = np.linspace(0,20,21)\n",
    "    c, _, _ = np.histogram2d(sizes[:, 0], sizes[:, 1], bins=(b, b))\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Load all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_sgs = []\n",
    "\n",
    "num_clusters = []\n",
    "num_tracks = []\n",
    "num_cands = []\n",
    "num_blocks = []\n",
    "\n",
    "blsize_candsize_matrices = []\n",
    "\n",
    "for fi in glob.glob(\"../data/TTbar/*ev*.npz\")[:10]:\n",
    "    fi = open(fi, \"rb\")\n",
    "    data = np.load(fi)\n",
    "    \n",
    "    #list of PF input elements in the event\n",
    "    X = data[\"elements\"]\n",
    "    \n",
    "    #tracks have type=1\n",
    "    num_clusters += [np.sum(X[:, 0] != 1)]\n",
    "    num_tracks += [np.sum(X[:, 0] == 1)]\n",
    "    \n",
    "    #unique ID for each cluster/block of elements that the PFAlgo considered independently\n",
    "    #this can be considered as the target output of an improved PFBlockAlgo\n",
    "    y = data[\"element_block_id\"]\n",
    "    num_blocks += [len(np.unique(y))]\n",
    "\n",
    "    #List of candidates produced in the event.\n",
    "    #This can be considered as the output of PFAlgo\n",
    "    cands = data[\"candidates\"]\n",
    "    num_cands += [len(cands)]\n",
    "\n",
    "    #get the types of the elements for each cluster/block\n",
    "    sgs = [tuple(get_types_in_block(X, y, blk)) for blk in np.unique(y)]\n",
    "    all_sgs += sgs\n",
    "    \n",
    "    blsize_candsize_matrices += [get_blocksize_candsize_matrix(data[\"element_block_id\"], data[\"candidate_block_id\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0,20,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "cmat = sum(blsize_candsize_matrices)\n",
    "plt.imshow(cmat, norm=LogNorm(vmin=1, vmax=10*np.sum(cmat)), origin=\"lower\", interpolation=None)\n",
    "\n",
    "plt.colorbar()\n",
    "plt.xticks(bins);\n",
    "plt.yticks(bins);\n",
    "\n",
    "plt.title(\"Miniblock size to number of\\nproduced PFCandidates\")\n",
    "plt.xlabel(\"number of candidates\")\n",
    "plt.ylabel(\"number of elements in block\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bins[:-1], cmat.sum(axis=1).cumsum()/np.sum(cmat), marker=\"o\")\n",
    "plt.xticks(bins);\n",
    "plt.xlabel(\"maximum block size\")\n",
    "plt.ylabel(\"fraction of candidates\")\n",
    "plt.xlim(0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bins[:-1], cmat.sum(axis=1).cumsum()/np.sum(cmat), marker=\"o\")\n",
    "plt.xticks(bins);\n",
    "plt.xlabel(\"maximum block size\")\n",
    "plt.ylabel(\"fraction of candidates\")\n",
    "plt.ylim(0.9, 1.0)\n",
    "plt.xlim(2,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(num_clusters, bins=np.linspace(0, 5000, 100), label=\"clusters\", alpha=0.5);\n",
    "plt.hist(num_tracks, bins=np.linspace(0, 5000, 100), label=\"tracks\", alpha=0.5);\n",
    "plt.hist(num_blocks, bins=np.linspace(0, 5000, 100), label=\"blocks\", alpha=0.5);\n",
    "plt.hist(num_cands, bins=np.linspace(0, 5000, 100), label=\"candidates\", alpha=0.5);\n",
    "plt.legend()\n",
    "plt.xlabel(\"number of els/cands/blocks\")\n",
    "plt.ylabel(\"number of events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look at the number of blocks of a certain size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "block_sizes = Counter([len(sg) for sg in all_sgs])\n",
    "print(\"block sizes\", block_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist([len(sg) for sg in all_sgs], bins=np.linspace(0,100,101));\n",
    "plt.xlabel(\"block size\")\n",
    "plt.ylabel(\"Number of blocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist([len(sg) for sg in all_sgs], bins=np.linspace(0,100,101));\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"block size\")\n",
    "plt.ylabel(\"number of blocks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what the blocks f size, 1, 2, 3 and 4 are made of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_block_nelem(blocks_nelem):\n",
    "    kv = list(blocks_nelem.items())\n",
    "    xs = np.arange(len(kv))\n",
    "    ys = np.array([v for k, v in kv])\n",
    "\n",
    "    plt.bar(xs, ys)\n",
    "    plt.xticks(xs, [k for k, v in kv], rotation=90)\n",
    "    \n",
    "\n",
    "for blocksize in range(1,5):\n",
    "    sizes = [\",\".join(map(str, sg)) for sg in all_sgs if len(sg)==blocksize]\n",
    "    blocks_nelem = Counter(sizes)\n",
    "    print(\"{0}-element blocks\".format(blocksize), blocks_nelem)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.title(\"Blocks of size {0}: {1} ({2:.0f}%)\".format(blocksize, len(sizes), 100.0*len(sizes)/len(all_sgs)))\n",
    "    plot_block_nelem(blocks_nelem)\n",
    "    plt.xlabel(\"Block element types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the first 10 blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = open(\"../data/TTbar/step3_AOD_1_ev0.npz\", \"rb\")\n",
    "data = np.load(fi)\n",
    "\n",
    "dm = scipy.sparse.load_npz(open(\"../data/TTbar/step3_AOD_1_dist0.npz\", \"rb\")).todense()\n",
    "dm[dm==0] = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "block_ids = data[\"element_block_id\"]\n",
    "inds_elem = np.arange(len(data[\"elements\"]))\n",
    "inds_cand = np.arange(len(data[\"candidates\"]))\n",
    "for blk in np.unique(block_ids)[:20]:\n",
    "    candidates_from_block = data[\"candidate_block_id\"] == blk\n",
    "    elems_in_block = data[\"element_block_id\"] == blk\n",
    "    \n",
    "    print(\"in block\", blk, \"had the following elements: {0}\".format(get_types_in_block(data[\"elements\"], data[\"element_block_id\"], blk)))\n",
    "    for ielem in inds_elem[elems_in_block]:\n",
    "        print(\"  elements[{0}]: type={1} energy={2:.2f}\".format(ielem, int(data[\"elements\"][ielem, 0]), data[\"elements\"][ielem, 1]))\n",
    "    print(\"from which the following candidates were produced\")\n",
    "    for icand in inds_cand[candidates_from_block]:\n",
    "        print(\"  candidates[{0}]: pdgid={1} pt={2:.2f}\".format(icand, int(data[\"candidates\"][icand, 0]), data[\"candidates\"][icand, 1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NONE=0,\n",
    "# TRACK=1, \n",
    "# PS1=2, \n",
    "# PS2=3, \n",
    "# ECAL=4, \n",
    "# HCAL=5,\n",
    "# GSF=6,\n",
    "# BREM=7,\n",
    "# HFEM=8,\n",
    "# HFHAD=9,\n",
    "# SC=10,\n",
    "# HO=11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_with_dm_aspf(dm):       \n",
    "    dm2 = dm.copy()\n",
    "    dm2[dm2==999] = 0\n",
    "    dm2[dm2>0] = 1\n",
    "    g = nx.from_numpy_matrix(dm2)\n",
    "\n",
    "    block_id_aspf = np.zeros_like(data[\"element_block_id\"])\n",
    "    for ibl, conn in enumerate(nx.connected_components(g)):\n",
    "        block_id_aspf[np.array(list(conn), dtype=np.int32)] = ibl\n",
    "        \n",
    "    return block_id_aspf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def dist(points, i, j):\n",
    "    p0 = points[i]\n",
    "    p1 = points[j]\n",
    "    #dphi = np.mod(p0[1] - p1[1], 2*math.pi) - math.pi\n",
    "    dphi = p0[1] - p1[1]\n",
    "    dphi = np.mod(dphi + np.pi, 2*np.pi) - np.pi\n",
    "    deta = p0[0] - p1[0]\n",
    "    return np.sqrt(dphi**2 + deta**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def fill_local_density(points, points_data, dc=0.3):\n",
    "    points_data[:, 0] = 0\n",
    "    \n",
    "    Np = len(points)\n",
    "    for i in range(Np):\n",
    "        for j in range(Np):\n",
    "            d = dist(points, i, j)\n",
    "            if d < dc:\n",
    "                fact = 1.0 if i==j else 0.5\n",
    "                points_data[i, 0] += points_data[j, 1]*fact\n",
    "\n",
    "@numba.njit\n",
    "def find_nearest_higher(points, points_data):\n",
    "    Np = len(points)\n",
    "    \n",
    "    for i in range(Np):\n",
    "        delta = 999.0\n",
    "        nearestHigher = -1\n",
    "        \n",
    "        for j in range(Np):\n",
    "            d = dist(points, i, j)\n",
    "            if d < delta and points_data[j, 0] > points_data[i, 0]:\n",
    "                nearestHigher = j\n",
    "                delta = d\n",
    "\n",
    "        points_data[i, 2] = delta\n",
    "        points_data[i, 3] = nearestHigher\n",
    "        \n",
    "\n",
    "def assign_cluster_id(points, points_types, points_data, rho_crit=10, delta_crit=0.2):\n",
    "    cluster_id = -1*np.ones((len(points),), dtype=np.int32)\n",
    "    Np = len(points)\n",
    "    nClusters = 0\n",
    "    \n",
    "    buffer_seeds = []\n",
    "    followers = {i: [] for i in range(Np)}\n",
    "    \n",
    "    for i in range(Np):\n",
    "        isSeed = (points_data[i, 0] > rho_crit) and (points_data[i, 2] > delta_crit)\n",
    "        isOutlier = (points_data[i, 0] <= rho_crit) and (points_data[i, 2] > 2*delta_crit)\n",
    "        #isOutlier = False\n",
    "        \n",
    "        if isSeed:\n",
    "            cluster_id[i] = nClusters\n",
    "            nClusters += 1\n",
    "            buffer_seeds += [i]\n",
    "        else:\n",
    "            if not isOutlier:\n",
    "                #add as a follower to the nearest highest point\n",
    "                nearestHighest = points_data[i, 3]\n",
    "                if nearestHighest != -1:\n",
    "                    followers[nearestHighest] += [i]\n",
    "    \n",
    "    #Now set the cluster ID for all children of all seeds\n",
    "    while len(buffer_seeds) > 0:\n",
    "        i = buffer_seeds.pop()\n",
    "        for fl in followers[i]:\n",
    "            cluster_id[fl] = cluster_id[i]\n",
    "            buffer_seeds += [fl]\n",
    "\n",
    "    return cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters_clue(data, weight_track, weight_hcal, weight_ecal, rho_crit, delta_crit):\n",
    "\n",
    "    clid_all_layers = -1*np.ones((len(data[\"elements\"]), 3), dtype=np.int32)\n",
    "\n",
    "    #Cluster HCAL to TRK\n",
    "    msk_trks_hcal = find_tracks_in_hcal(data[\"elements\"])\n",
    "    inds_trks_hcal = np.where(msk_trks_hcal)[0]\n",
    "    trks_hcal = data[\"elements\"][msk_trks_hcal, 6:8]\n",
    "\n",
    "    msk_hcal_clusters = find_hcal_clusters(data[\"elements\"])\n",
    "    hcal_clusters = data[\"elements\"][msk_hcal_clusters, 2:4]\n",
    "    inds_hcal_clusters = np.where(msk_hcal_clusters)[0]\n",
    "    \n",
    "    points = np.vstack([trks_hcal, hcal_clusters])\n",
    "    inds = np.hstack([inds_trks_hcal, inds_hcal_clusters])\n",
    "    points_types = np.hstack([data[\"elements\"][msk_trks_hcal][:, 0], data[\"elements\"][msk_hcal_clusters][:, 0]])\n",
    "\n",
    "    #rho, weight, delta, nearestHigher\n",
    "    points_data = np.zeros((len(points), 4))\n",
    "    points_data[:, 1] = 1.0\n",
    "    points_data[points_types==1, 1] = weight_track\n",
    "    points_data[points_types==5, 1] = weight_hcal\n",
    "\n",
    "    fill_local_density(points, points_data)\n",
    "    find_nearest_higher(points, points_data)\n",
    "    clid_trk_hcal = assign_cluster_id(points, points_types, points_data, rho_crit=rho_crit, delta_crit=delta_crit)\n",
    "    \n",
    "    for i in range(len(inds)):\n",
    "        clid_all_layers[inds[i], 0] = clid_trk_hcal[i]\n",
    "        \n",
    "    #Cluster ECAL to TRK\n",
    "    msk_trks_ecal = find_tracks_in_ecal(data[\"elements\"])\n",
    "    inds_trks_ecal = np.where(msk_trks_ecal)[0]\n",
    "    trks_ecal = data[\"elements\"][msk_trks_ecal, 4:6]\n",
    "\n",
    "    msk_ecal_clusters = find_ecal_clusters(data[\"elements\"])\n",
    "    ecal_clusters = data[\"elements\"][msk_ecal_clusters, 2:4]\n",
    "    inds_ecal_clusters = np.where(msk_ecal_clusters)[0]\n",
    "\n",
    "    points = np.vstack([trks_ecal, ecal_clusters])\n",
    "    inds = np.hstack([inds_trks_ecal, inds_ecal_clusters])\n",
    "    points_types = np.hstack([data[\"elements\"][msk_trks_ecal][:, 0], data[\"elements\"][msk_ecal_clusters][:, 0]])\n",
    "\n",
    "    #rho, weight, delta, nearestHigher\n",
    "    points_data = np.zeros((len(points), 4))\n",
    "    points_data[:, 1] = 1.0\n",
    "    points_data[points_types==1, 1] = weight_track\n",
    "    points_data[points_types==4, 1] = weight_ecal\n",
    "\n",
    "    fill_local_density(points, points_data)\n",
    "    find_nearest_higher(points, points_data)\n",
    "    clid_trk_ecal = assign_cluster_id(points, points_types, points_data, rho_crit=rho_crit, delta_crit=delta_crit)\n",
    "    clid_trk_ecal += np.max(clid_trk_hcal) + 1\n",
    "    \n",
    "    for i in range(len(inds)):\n",
    "        clid_all_layers[inds[i], 1] = clid_trk_ecal[i]\n",
    "        \n",
    "    return clid_all_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = []\n",
    "for iev in range(500):\n",
    "    fi = open(\"../data/TTbar/step3_AOD_1_ev{0}.npz\".format(iev), \"rb\")\n",
    "    data = np.load(fi)\n",
    "    datas += [{\"elements\": data[\"elements\"], \"element_block_id\": data[\"element_block_id\"]}]\n",
    "    fi.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = open(\"../data/TTbar/step3_AOD_1_ev{0}.npz\".format(0), \"rb\")\n",
    "data = np.load(fi)\n",
    "fi2 = open(\"../data/TTbar/step3_AOD_1_dist{0}.npz\".format(0), \"rb\")\n",
    "dm = scipy.sparse.load_npz(fi2).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_points(elements, block_id):\n",
    "    Npoints = 100000\n",
    "    Nlinks = 100000\n",
    "\n",
    "    #id, type, layer, block_id, cluster_id\n",
    "    points_data = np.zeros((Npoints, 5), dtype=np.int64)\n",
    "\n",
    "    #eta, phi\n",
    "    points_pos = np.zeros((Npoints, 2), dtype=np.float32)\n",
    "\n",
    "    point_to_point_link = np.zeros((Nlinks, 2), dtype=np.int64)\n",
    "\n",
    "    ip = 0\n",
    "    ilink = 0\n",
    "    for iel in range(len(elements)):\n",
    "        tp = elements[iel, 0]\n",
    "        if tp == 1 or tp == 6:\n",
    "            in_tracker = (elements[iel, 2]!=0) and (elements[iel, 3]!=0)\n",
    "            in_ecal = (elements[iel, 4]!=0) and (elements[iel, 5]!=0)\n",
    "            in_hcal = (elements[iel, 6]!=0) and (elements[iel, 7]!=0)\n",
    "            if in_tracker:\n",
    "                points_data[ip, 0] = ip\n",
    "                points_data[ip, 1] = tp\n",
    "                points_data[ip, 2] = 0\n",
    "                points_data[ip, 3] = block_id[iel]\n",
    "                points_data[ip, 4] = -1\n",
    "                points_pos[ip, 0] = elements[iel, 2]\n",
    "                points_pos[ip, 1] = elements[iel, 3]\n",
    "                ip += 1\n",
    "            if in_ecal:\n",
    "                points_data[ip, 0] = ip\n",
    "                points_data[ip, 1] = tp\n",
    "                points_data[ip, 2] = 1\n",
    "                points_data[ip, 3] = block_id[iel]\n",
    "                points_data[ip, 4] = -1\n",
    "                points_pos[ip, 0] = elements[iel, 4]\n",
    "                points_pos[ip, 1] = elements[iel, 5]\n",
    "                if in_tracker:\n",
    "                    point_to_point_link[ilink, 0] = ip-1\n",
    "                    point_to_point_link[ilink, 1] = ip\n",
    "                    ilink += 1\n",
    "                ip += 1\n",
    "            if in_hcal:\n",
    "                points_data[ip, 0] = ip\n",
    "                points_data[ip, 1] = tp\n",
    "                points_data[ip, 2] = 2\n",
    "                points_data[ip, 3] = block_id[iel]\n",
    "                points_data[ip, 4] = -1\n",
    "                points_pos[ip, 0] = elements[iel, 6]\n",
    "                points_pos[ip, 1] = elements[iel, 7]\n",
    "                if in_ecal:\n",
    "                    point_to_point_link[ilink, 0] = ip-1\n",
    "                    point_to_point_link[ilink, 1] = ip\n",
    "                    ilink += 1\n",
    "                ip += 1\n",
    "        else:\n",
    "            layer = 1\n",
    "            if tp == 5:\n",
    "                layer = 2\n",
    "            elif tp >= 8:\n",
    "                layer = 3\n",
    "            points_data[ip, 0] = ip\n",
    "            points_data[ip, 1] = tp\n",
    "            points_data[ip, 2] = layer\n",
    "            points_data[ip, 3] = block_id[iel]\n",
    "            points_data[ip, 4] = -1\n",
    "            points_pos[ip, 0] = elements[iel, 2]\n",
    "            points_pos[ip, 1] = elements[iel, 3]\n",
    "            ip += 1\n",
    "\n",
    "    points_data = points_data[:ip]\n",
    "    points_pos = points_pos[:ip]\n",
    "    point_to_point_link = point_to_point_link[:ilink]\n",
    "    \n",
    "    return points_data, points_pos, point_to_point_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(points_data, points_pos):\n",
    "    df = pandas.DataFrame(points_data.copy(),\n",
    "        columns=[\"id\", \"type\", \"layer\", \"block_id\", \"cluster_id\"],\n",
    "        index=points_data[:, 0])\n",
    "    df[\"pos_eta\"] = np.array(points_pos[:, 0])\n",
    "    df[\"pos_phi\"] = np.array(points_pos[:, 1])\n",
    "    df[\"size\"] = 1\n",
    "    df[\"symbol\"] = \"dot\"\n",
    "    df[\"color\"] = df[\"type\"]\n",
    "    df[\"layer\"] = 1 + 2*df[\"layer\"]\n",
    "\n",
    "    df[\"pos_x\"] = 2*df[\"pos_eta\"]\n",
    "    df[\"pos_y\"] = df[\"layer\"]*np.cos(df[\"pos_phi\"])\n",
    "    df[\"pos_z\"] = df[\"layer\"]*np.sin(df[\"pos_phi\"])\n",
    "\n",
    "    df.loc[df[\"type\"]==1, \"size\"] = 0.2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_largest_blocks(block_ids, highlight_blocks):\n",
    "    colors = []\n",
    "    cols_to_take = [\"red\", \"green\", \"blue\", \"orange\", \"purple\"]\n",
    "    colmap = {t: cols_to_take.pop() for t in highlight_blocks}\n",
    "    for i in block_ids:\n",
    "        if i in highlight_blocks:\n",
    "            colors.append(colmap[i])\n",
    "        else:\n",
    "            colors.append(\"gray\")\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import colorlover as cl\n",
    "\n",
    "def draw_plot(dfsel, highlight_blocks, point_to_point_link):\n",
    "    msk_blocks = np.vstack([dfsel[\"block_id\"] == b for b in highlight_blocks]).sum(axis=0)>=1\n",
    "    trk = (dfsel[\"type\"]==1) | (dfsel[\"type\"]==6)\n",
    "\n",
    "    points_trk_blk = go.Scatter3d(\n",
    "        x=dfsel.loc[trk&msk_blocks, 'pos_x'].values,\n",
    "        y=dfsel.loc[trk&msk_blocks, 'pos_y'].values,\n",
    "        z=dfsel.loc[trk&msk_blocks, 'pos_z'].values,\n",
    "        mode=\"markers\",\n",
    "        marker={\n",
    "            \"symbol\": \"cross\",\n",
    "            \"opacity\": 0.8,\n",
    "            \"size\": 5,\n",
    "            \"color\": color_largest_blocks(dfsel.loc[trk&msk_blocks, \"block_id\"], highlight_blocks),\n",
    "            #\"colorscale\": cl.scales['11']['qual'][\"Set3\"]\n",
    "        },\n",
    "        name=\"track point in block\"\n",
    "    )\n",
    "\n",
    "    points_trk = go.Scatter3d(\n",
    "        x=dfsel.loc[trk&~msk_blocks, 'pos_x'].values,\n",
    "        y=dfsel.loc[trk&~msk_blocks, 'pos_y'].values,\n",
    "        z=dfsel.loc[trk&~msk_blocks, 'pos_z'].values,\n",
    "        mode=\"markers\",\n",
    "        marker={\n",
    "            \"symbol\": \"cross\",\n",
    "            \"opacity\": 0.05,\n",
    "            \"size\": 5,\n",
    "            \"color\": \"gray\"\n",
    "            #\"colorscale\": cl.scales['11']['qual'][\"Set3\"]\n",
    "        },\n",
    "        name=\"track point\"\n",
    "    )\n",
    "\n",
    "    points_other_blk = go.Scatter3d(\n",
    "        x=dfsel.loc[(~trk)&msk_blocks, 'pos_x'].values,\n",
    "        y=dfsel.loc[(~trk)&msk_blocks, 'pos_y'].values,\n",
    "        z=dfsel.loc[(~trk)&msk_blocks, 'pos_z'].values,\n",
    "        mode=\"markers\",\n",
    "        marker={\n",
    "            \"symbol\": \"circle\",\n",
    "            \"opacity\": 0.8,\n",
    "            \"size\": 5,\n",
    "            \"color\": color_largest_blocks(dfsel.loc[~trk&msk_blocks, \"block_id\"], highlight_blocks),\n",
    "        },\n",
    "        name=\"calo cluster in block\"\n",
    "    )\n",
    "\n",
    "\n",
    "    points_other = go.Scatter3d(\n",
    "        x=dfsel.loc[~trk&~msk_blocks, 'pos_x'].values,\n",
    "        y=dfsel.loc[~trk&~msk_blocks, 'pos_y'].values,\n",
    "        z=dfsel.loc[~trk&~msk_blocks, 'pos_z'].values,\n",
    "        mode=\"markers\",\n",
    "        marker={\n",
    "            \"symbol\": \"circle\",\n",
    "            \"opacity\": 0.05,\n",
    "            \"size\": 5,\n",
    "            \"color\": \"gray\"\n",
    "        },\n",
    "        name=\"calo cluster\"\n",
    "    )\n",
    "\n",
    "    line_points_x = []\n",
    "    line_points_y = []\n",
    "    line_points_z = []\n",
    "    \n",
    "    for ip in np.array(range(len(point_to_point_link))):\n",
    "        p0 = point_to_point_link[ip, 0]\n",
    "        p1 = point_to_point_link[ip, 1]\n",
    "        if dfsel.loc[p0, \"block_id\"] in highlight_blocks or dfsel.loc[p1, \"block_id\"] in highlight_blocks:\n",
    "            if p0 in dfsel.index and p1 in dfsel.index:\n",
    "                line_points_x += [dfsel.loc[p0, \"pos_x\"], dfsel.loc[p1, \"pos_x\"], None]\n",
    "                line_points_y += [dfsel.loc[p0, \"pos_y\"], dfsel.loc[p1, \"pos_y\"], None]\n",
    "                line_points_z += [dfsel.loc[p0, \"pos_z\"], dfsel.loc[p1, \"pos_z\"], None]\n",
    "\n",
    "    tracks = go.Scatter3d(\n",
    "        x=line_points_x,\n",
    "        y=line_points_y,\n",
    "        z=line_points_z,\n",
    "        mode=\"lines\",\n",
    "        opacity=0.2,\n",
    "        line={\"color\": \"black\"},\n",
    "        name=\"track between layers\")\n",
    "\n",
    "    fig = go.Figure(data=[\n",
    "        points_trk,\n",
    "        points_other,\n",
    "        points_trk_blk,\n",
    "        points_other_blk,\n",
    "        tracks\n",
    "    ])\n",
    "\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=1000,\n",
    "        height=500,\n",
    "        margin=go.layout.Margin(\n",
    "            l=0,\n",
    "            r=0,\n",
    "            b=0,\n",
    "            t=0,\n",
    "        ),\n",
    "        title=\"asd\"\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_data, points_pos, point_to_point_link = create_points(\n",
    "    data[\"elements\"], data[\"element_block_id\"]\n",
    ")\n",
    "\n",
    "points_data2, points_pos2, point_to_point_link2 = create_points(\n",
    "    data[\"elements\"], cluster_with_dm_aspf(dm)\n",
    ")\n",
    "\n",
    "df = make_df(points_data, points_pos)\n",
    "df2 = make_df(points_data2, points_pos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_blocks = sorted(Counter(df[\"block_id\"][df[\"type\"]==1]).items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "largest_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plot(df, [137, 40, 117], point_to_point_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_blocks = sorted(Counter(df2[\"block_id\"][df2[\"type\"]==1]).items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "largest_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plot(df2, [0, 1, 5, 10], point_to_point_link2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
