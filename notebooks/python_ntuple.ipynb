{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numba\n",
    "from collections import Counter\n",
    "import math\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import sklearn.ensemble\n",
    "import sklearn.cluster\n",
    "import scipy.sparse\n",
    "import keras\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib\n",
    "\n",
    "sys.path += [\"../test\"]\n",
    "from train_clustering import encode_triu, decode_triu\n",
    "from train_regression import get_unique_X_y\n",
    "\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def get_types_in_block(X, y, blk):\n",
    "    return [int(x) for x in sorted(X[y==blk, 0])]\n",
    "\n",
    "def get_blocksize_candsize_matrix(el_bl_id, cand_bl_id):\n",
    "    blids = np.unique(el_bl_id)\n",
    "    sizes = np.zeros((len(blids), 2), dtype=np.float32)\n",
    "    i = 0\n",
    "    els_counter = Counter(el_bl_id)\n",
    "    cands_counter = Counter(cand_bl_id)\n",
    "    for bl in blids:\n",
    "        sizes[i, 0] = els_counter[bl]\n",
    "        sizes[i, 1] = cands_counter[bl]\n",
    "        i += 1\n",
    "        \n",
    "    b = np.linspace(0,20,21)\n",
    "    c, _, _ = np.histogram2d(sizes[:, 0], sizes[:, 1], bins=(b, b))\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Load all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_sgs = []\n",
    "\n",
    "num_clusters = []\n",
    "num_tracks = []\n",
    "num_cands = []\n",
    "num_blocks = []\n",
    "\n",
    "blsize_candsize_matrices = []\n",
    "\n",
    "for fi in glob.glob(\"../data/TTbar/*ev*.npz\")[:10]:\n",
    "    fi = open(fi, \"rb\")\n",
    "    data = np.load(fi)\n",
    "    \n",
    "    #list of PF input elements in the event\n",
    "    X = data[\"elements\"]\n",
    "    \n",
    "    #tracks have type=1\n",
    "    num_clusters += [np.sum(X[:, 0] != 1)]\n",
    "    num_tracks += [np.sum(X[:, 0] == 1)]\n",
    "    \n",
    "    #unique ID for each cluster/block of elements that the PFAlgo considered independently\n",
    "    #this can be considered as the target output of an improved PFBlockAlgo\n",
    "    y = data[\"element_block_id\"]\n",
    "    num_blocks += [len(np.unique(y))]\n",
    "\n",
    "    #List of candidates produced in the event.\n",
    "    #This can be considered as the output of PFAlgo\n",
    "    cands = data[\"candidates\"]\n",
    "    num_cands += [len(cands)]\n",
    "\n",
    "    #get the types of the elements for each cluster/block\n",
    "    sgs = [tuple(get_types_in_block(X, y, blk)) for blk in np.unique(y)]\n",
    "    all_sgs += sgs\n",
    "    \n",
    "    blsize_candsize_matrices += [get_blocksize_candsize_matrix(data[\"element_block_id\"], data[\"candidate_block_id\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0,20,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "cmat = sum(blsize_candsize_matrices)\n",
    "plt.imshow(cmat, norm=LogNorm(vmin=1, vmax=10*np.sum(cmat)), origin=\"lower\", interpolation=None)\n",
    "\n",
    "plt.colorbar()\n",
    "plt.xticks(bins);\n",
    "plt.yticks(bins);\n",
    "\n",
    "plt.title(\"Miniblock size to number of\\nproduced PFCandidates\")\n",
    "plt.xlabel(\"number of candidates\")\n",
    "plt.ylabel(\"number of elements in block\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bins[:-1], cmat.sum(axis=1).cumsum()/np.sum(cmat), marker=\"o\")\n",
    "plt.xticks(bins);\n",
    "plt.xlabel(\"maximum block size\")\n",
    "plt.ylabel(\"fraction of candidates\")\n",
    "plt.xlim(0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bins[:-1], cmat.sum(axis=1).cumsum()/np.sum(cmat), marker=\"o\")\n",
    "plt.xticks(bins);\n",
    "plt.xlabel(\"maximum block size\")\n",
    "plt.ylabel(\"fraction of candidates\")\n",
    "plt.ylim(0.9, 1.0)\n",
    "plt.xlim(2,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(num_clusters, bins=np.linspace(0, 5000, 100), label=\"clusters\", alpha=0.5);\n",
    "plt.hist(num_tracks, bins=np.linspace(0, 5000, 100), label=\"tracks\", alpha=0.5);\n",
    "plt.hist(num_blocks, bins=np.linspace(0, 5000, 100), label=\"blocks\", alpha=0.5);\n",
    "plt.hist(num_cands, bins=np.linspace(0, 5000, 100), label=\"candidates\", alpha=0.5);\n",
    "plt.legend()\n",
    "plt.xlabel(\"number of els/cands/blocks\")\n",
    "plt.ylabel(\"number of events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look at the number of blocks of a certain size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "block_sizes = Counter([len(sg) for sg in all_sgs])\n",
    "print(\"block sizes\", block_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist([len(sg) for sg in all_sgs], bins=np.linspace(0,100,101));\n",
    "plt.xlabel(\"block size\")\n",
    "plt.ylabel(\"Number of blocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist([len(sg) for sg in all_sgs], bins=np.linspace(0,100,101));\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"block size\")\n",
    "plt.ylabel(\"number of blocks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what the blocks f size, 1, 2, 3 and 4 are made of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_block_nelem(blocks_nelem):\n",
    "    kv = list(blocks_nelem.items())\n",
    "    xs = np.arange(len(kv))\n",
    "    ys = np.array([v for k, v in kv])\n",
    "\n",
    "    plt.bar(xs, ys)\n",
    "    plt.xticks(xs, [k for k, v in kv], rotation=90)\n",
    "    \n",
    "\n",
    "for blocksize in range(1,5):\n",
    "    sizes = [\",\".join(map(str, sg)) for sg in all_sgs if len(sg)==blocksize]\n",
    "    blocks_nelem = Counter(sizes)\n",
    "    print(\"{0}-element blocks\".format(blocksize), blocks_nelem)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.title(\"Blocks of size {0}: {1} ({2:.0f}%)\".format(blocksize, len(sizes), 100.0*len(sizes)/len(all_sgs)))\n",
    "    plot_block_nelem(blocks_nelem)\n",
    "    plt.xlabel(\"Block element types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the first 10 blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = open(\"../data/TTbar/step3_AOD_1_ev0.npz\", \"rb\")\n",
    "data = np.load(fi)\n",
    "\n",
    "dm = scipy.sparse.load_npz(open(\"../data/TTbar/step3_AOD_1_dist0.npz\", \"rb\")).todense()\n",
    "dm[dm==0] = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "block_ids = data[\"element_block_id\"]\n",
    "inds_elem = np.arange(len(data[\"elements\"]))\n",
    "inds_cand = np.arange(len(data[\"candidates\"]))\n",
    "for blk in np.unique(block_ids)[:20]:\n",
    "    candidates_from_block = data[\"candidate_block_id\"] == blk\n",
    "    elems_in_block = data[\"element_block_id\"] == blk\n",
    "    \n",
    "    print(\"in block\", blk, \"had the following elements: {0}\".format(get_types_in_block(data[\"elements\"], data[\"element_block_id\"], blk)))\n",
    "    for ielem in inds_elem[elems_in_block]:\n",
    "        print(\"  elements[{0}]: type={1} energy={2:.2f}\".format(ielem, int(data[\"elements\"][ielem, 0]), data[\"elements\"][ielem, 1]))\n",
    "    print(\"from which the following candidates were produced\")\n",
    "    for icand in inds_cand[candidates_from_block]:\n",
    "        print(\"  candidates[{0}]: pdgid={1} pt={2:.2f}\".format(icand, int(data[\"candidates\"][icand, 0]), data[\"candidates\"][icand, 1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NONE=0,\n",
    "# TRACK=1, \n",
    "# PS1=2, \n",
    "# PS2=3, \n",
    "# ECAL=4, \n",
    "# HCAL=5,\n",
    "# GSF=6,\n",
    "# BREM=7,\n",
    "# HFEM=8,\n",
    "# HFHAD=9,\n",
    "# SC=10,\n",
    "# HO=11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = []\n",
    "for iev in range(500):\n",
    "    fi = open(\"../data/TTbar/step3_AOD_1_ev{0}.npz\".format(iev), \"rb\")\n",
    "    data = np.load(fi)\n",
    "    datas += [{\"elements\": data[\"elements\"], \"element_block_id\": data[\"element_block_id\"]}]\n",
    "    fi.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iev = 1\n",
    "fi = open(\"../data/TTbar/step3_AOD_1_ev{0}.npz\".format(iev), \"rb\")\n",
    "data = np.load(fi)\n",
    "fi2 = open(\"../data/TTbar/step3_AOD_1_dist{0}.npz\".format(iev), \"rb\")\n",
    "dm = scipy.sparse.load_npz(fi2).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(points_data, points_pos):\n",
    "    df = pandas.DataFrame(points_data.copy(),\n",
    "        columns=[\"id\", \"type\", \"layer\", \"block_id\", \"cluster_id\"],\n",
    "        index=points_data[:, 0])\n",
    "    df[\"pos_eta\"] = np.array(points_pos[:, 0])\n",
    "    df[\"pos_phi\"] = np.array(points_pos[:, 1])\n",
    "    df[\"energy\"] = np.array(points_pos[:, 2])\n",
    "    df[\"size\"] = 1\n",
    "    df[\"symbol\"] = \"dot\"\n",
    "    df[\"color\"] = df[\"type\"]\n",
    "    df[\"layer\"] = 1 + 2*df[\"layer\"]\n",
    "\n",
    "    df[\"pos_x\"] = 2*df[\"pos_eta\"]\n",
    "    df[\"pos_y\"] = df[\"layer\"]*np.cos(df[\"pos_phi\"])\n",
    "    df[\"pos_z\"] = df[\"layer\"]*np.sin(df[\"pos_phi\"])\n",
    "\n",
    "    df.loc[df[\"type\"]==1, \"size\"] = 0.2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def color_largest_blocks(block_ids, highlight_blocks):\n",
    "    colors = []\n",
    "    cols_to_take = itertools.cycle([\"red\", \"green\", \"blue\", \"orange\", \"purple\", \"cyan\", \"yellow\", \"brown\"])\n",
    "    colmap = {t: next(cols_to_take) for t in highlight_blocks}\n",
    "    for i in block_ids:\n",
    "        if i in highlight_blocks:\n",
    "            colors.append(colmap[i])\n",
    "        else:\n",
    "            colors.append(\"gray\")\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import colorlover as cl\n",
    "\n",
    "def draw_plot(dfsel, highlight_blocks, point_to_point_link, title, layers_to_plot=[1,3,5,7]):\n",
    "    \n",
    "    \n",
    "    msk_blocks = np.vstack([dfsel[\"block_id\"] == b for b in highlight_blocks]).sum(axis=0)>=1\n",
    "    msk_layers = np.vstack([dfsel[\"layer\"] == b for b in layers_to_plot]).sum(axis=0)>=1\n",
    "    \n",
    "    trk = (dfsel[\"type\"]==1) | (dfsel[\"type\"]==6)\n",
    "\n",
    "    points_trk_blk = go.Scatter3d(\n",
    "        x=dfsel.loc[trk & msk_blocks & msk_layers, 'pos_x'].values,\n",
    "        y=dfsel.loc[trk&msk_blocks & msk_layers, 'pos_y'].values,\n",
    "        z=dfsel.loc[trk&msk_blocks & msk_layers, 'pos_z'].values,\n",
    "        mode=\"markers\",\n",
    "        marker={\n",
    "            \"symbol\": \"cross\",\n",
    "            \"opacity\": 0.8,\n",
    "            \"size\": 5,\n",
    "            \"color\": color_largest_blocks(dfsel.loc[trk&msk_blocks, \"block_id\"], highlight_blocks),\n",
    "            #\"colorscale\": cl.scales['11']['qual'][\"Set3\"]\n",
    "        },\n",
    "        name=\"track point in block\"\n",
    "    )\n",
    "\n",
    "    points_trk = go.Scatter3d(\n",
    "        x=dfsel.loc[trk & ~msk_blocks, 'pos_x'].values,\n",
    "        y=dfsel.loc[trk & ~msk_blocks, 'pos_y'].values,\n",
    "        z=dfsel.loc[trk & ~msk_blocks, 'pos_z'].values,\n",
    "        mode=\"markers\",\n",
    "        marker={\n",
    "            \"symbol\": \"cross\",\n",
    "            \"opacity\": 0.05,\n",
    "            \"size\": 5,\n",
    "            \"color\": \"gray\"\n",
    "            #\"colorscale\": cl.scales['11']['qual'][\"Set3\"]\n",
    "        },\n",
    "        name=\"track point\"\n",
    "    )\n",
    "\n",
    "    points_other_blk = go.Scatter3d(\n",
    "        x=dfsel.loc[(~trk) & msk_blocks & msk_layers, 'pos_x'].values,\n",
    "        y=dfsel.loc[(~trk) & msk_blocks & msk_layers, 'pos_y'].values,\n",
    "        z=dfsel.loc[(~trk) & msk_blocks & msk_layers, 'pos_z'].values,\n",
    "        mode=\"markers\",\n",
    "        marker={\n",
    "            \"symbol\": \"circle\",\n",
    "            \"opacity\": 0.8,\n",
    "            \"size\": 5,\n",
    "            \"color\": color_largest_blocks(dfsel.loc[~trk&msk_blocks, \"block_id\"], highlight_blocks),\n",
    "        },\n",
    "        name=\"calo cluster in block\"\n",
    "    )\n",
    "\n",
    "\n",
    "    points_other = go.Scatter3d(\n",
    "        x=dfsel.loc[~trk & ~msk_blocks, 'pos_x'].values,\n",
    "        y=dfsel.loc[~trk & ~msk_blocks, 'pos_y'].values,\n",
    "        z=dfsel.loc[~trk & ~msk_blocks, 'pos_z'].values,\n",
    "        mode=\"markers\",\n",
    "        marker={\n",
    "            \"symbol\": \"circle\",\n",
    "            \"opacity\": 0.05,\n",
    "            \"size\": 5,\n",
    "            \"color\": \"gray\"\n",
    "        },\n",
    "        name=\"calo cluster\"\n",
    "    )\n",
    "\n",
    "    line_points_x = []\n",
    "    line_points_y = []\n",
    "    line_points_z = []\n",
    "    \n",
    "    line_points_x_all = []\n",
    "    line_points_y_all = []\n",
    "    line_points_z_all = []\n",
    "    \n",
    "    for ip in np.array(range(len(point_to_point_link))):\n",
    "        p0 = point_to_point_link[ip, 0]\n",
    "        p1 = point_to_point_link[ip, 1]\n",
    "        line_points_x += [dfsel.loc[p0, \"pos_x\"], dfsel.loc[p1, \"pos_x\"], None]\n",
    "                line_points_y += [dfsel.loc[p0, \"pos_y\"], dfsel.loc[p1, \"pos_y\"], None]\n",
    "                line_points_z += [dfsel.loc[p0, \"pos_z\"], dfsel.loc[p1, \"pos_z\"], None]\n",
    "        if dfsel.loc[p0, \"block_id\"] in highlight_blocks or dfsel.loc[p1, \"block_id\"] in highlight_blocks:\n",
    "            if p0 in dfsel.index and p1 in dfsel.index:\n",
    "                line_points_x += [dfsel.loc[p0, \"pos_x\"], dfsel.loc[p1, \"pos_x\"], None]\n",
    "                line_points_y += [dfsel.loc[p0, \"pos_y\"], dfsel.loc[p1, \"pos_y\"], None]\n",
    "                line_points_z += [dfsel.loc[p0, \"pos_z\"], dfsel.loc[p1, \"pos_z\"], None]\n",
    "\n",
    "\n",
    "    tracks = go.Scatter3d(\n",
    "        x=line_points_x,\n",
    "        y=line_points_y,\n",
    "        z=line_points_z,\n",
    "        mode=\"lines\",\n",
    "        opacity=0.2,\n",
    "        line={\"color\": \"black\"},\n",
    "        name=\"track between layers\")\n",
    "\n",
    "    fig = go.Figure(data=[\n",
    "        points_trk,\n",
    "        points_other,\n",
    "        points_trk_blk,\n",
    "        points_other_blk,\n",
    "        tracks\n",
    "    ])\n",
    "\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=1000,\n",
    "        height=500,\n",
    "        margin=go.layout.Margin(\n",
    "            l=0,\n",
    "            r=0,\n",
    "            b=0,\n",
    "            t=50,\n",
    "        ),\n",
    "        title=title,\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_data, points_pos, point_to_point_link = create_points(\n",
    "    data[\"elements\"], data[\"element_block_id\"]\n",
    ")\n",
    "\n",
    "points_data2, points_pos2, point_to_point_link2 = create_points(\n",
    "    data[\"elements\"], cluster_with_dm_aspf(dm)\n",
    ")\n",
    "\n",
    "df = make_df(points_data, points_pos)\n",
    "df2 = make_df(points_data2, points_pos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df[\"layer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_blocks = sorted(Counter(df[\"block_id\"][df[\"type\"]==1]).items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "largest_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plot(df, [137, 40, 117], point_to_point_link, \"PFAlgo-based true blocks\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
